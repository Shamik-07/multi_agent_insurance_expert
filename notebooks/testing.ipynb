{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a43c4a-e36e-438e-a7ef-d6b6ed1e88e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:36:58.593607Z",
     "iopub.status.busy": "2025-05-25T11:36:58.592363Z",
     "iopub.status.idle": "2025-05-25T11:36:59.409700Z",
     "shell.execute_reply": "2025-05-25T11:36:59.408793Z",
     "shell.execute_reply.started": "2025-05-25T11:36:58.593527Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel, VisitWebpageTool, WikipediaSearchTool, FinalAnswerTool, PythonInterpreterTool,\n",
    "# import nest_asyncio\n",
    "\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e6e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import model_info, InferenceClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22296de",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    provider=\"hyperbolic\",\n",
    "    bill_to=\"VitalNest\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cec2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inference_models = !curl -s https://huggingface.co/api/models | jq \".[].id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e1c9797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warm'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "info = model_info(\"google/gemma-3-27b-it\", expand=\"inference\")\n",
    "info.inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc107e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm_model = InferenceClientModel(model_id=\"Qwen/Qwen2.5-VL-72B-Instruct\",bill_to=\"VitalNest\",\n",
    "                                 timeout=300,temperature=.1, max_tokens=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0c7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085aa7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: Base64 encoded image string.\n",
    "    \"\"\"\n",
    "    \"\"\"Encodes a PIL image to a base64 string.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f5b9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAXIMUM of 4 images can be sent\n",
    "img_paths = [\n",
    "    Path(\n",
    "        \"../src/pages/optima-restore-revision.pdf/optima-restore-revision.pdf_page_42.png\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"../src/pages/optima-restore-revision.pdf/optima-restore-revision.pdf_page_12.png\"\n",
    "    ),\n",
    "    Path(\n",
    "        \"../src/pages/optima-restore-revision.pdf/optima-restore-revision.pdf_page_1.png\"\n",
    "    ),\n",
    "    # Path(\n",
    "    #     \"../src/pages/optima-restore-revision.pdf/optima-restore-revision.pdf_page_43.png\"\n",
    "    # ),\n",
    "    # Path(\n",
    "    #     \"../src/pages/optima-restore-revision.pdf/optima-restore-revision.pdf_page_44.png\"\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73a61942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_images = [Image.open(fp=pth) for pth in img_paths]\n",
    "grouped_images = [encode_image_to_base64(pth) for pth in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fa8f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = \"\"\"what critical illnesses are covered under optima restore?\n",
    "If the answer isn't in these documents, say you don't know.\"\"\"\n",
    "chat_template = [\n",
    "    {\n",
    "\"role\":\"system\", \"content\":\"\"\"You find answers from the relevant documents. Answer only \n",
    "from these documents. If answer isn't available return 'Question cannot be answered based\n",
    "on the documents provided.' \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "            }\n",
    "            for image in grouped_images\n",
    "        ]\n",
    "        + [{\"type\": \"text\", \"text\": text_query}],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e6d672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical illnesses covered under Optima Restore include Cancer, Open Chest CABG, First Heart Attack, Kidney Failure, Major Organ/Bone Marrow Transplant, Multiple Sclerosis, Permanent Paralysis of Limbs, and Stroke.\n"
     ]
    }
   ],
   "source": [
    "print(vlm_model.generate(messages=chat_template).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f0477f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical illnesses covered under Optima Restore include Cancer, Open Chest CABG, First Heart Attack, Kidney Failure, Major Organ/Bone Marrow Transplant, Multiple Sclerosis, Permanent Paralysis of Limbs, and Stroke.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "    messages=chat_template,\n",
    "    temperature=.1,\n",
    "    max_tokens=10_000\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": [\n",
    "#                 {\"type\": \"text\", \"text\": \"Describe the images in one sentence.\"},\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": {\n",
    "#                         \"url\": \"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\"\n",
    "#                     },\n",
    "#                 },\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": {\n",
    "#                         \"url\": \"https://upload.wikimedia.org/wikipedia/commons/3/3d/Nicu%C8%99or_Dan_%288_mai_2025%29.jpg\"\n",
    "#                     },\n",
    "#                 },\n",
    "#             ],\n",
    "#         }\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5b826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ce44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a5c91b2-c3dc-4a38-8d12-23ebde2324d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:36:59.411663Z",
     "iopub.status.busy": "2025-05-25T11:36:59.410797Z",
     "iopub.status.idle": "2025-05-25T11:36:59.419560Z",
     "shell.execute_reply": "2025-05-25T11:36:59.418230Z",
     "shell.execute_reply.started": "2025-05-25T11:36:59.411622Z"
    }
   },
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class SaveContent(Tool):\n",
    "    name = \"SaveContent\"\n",
    "    description = \"Saves content to a file.\"\n",
    "    inputs = {\n",
    "        \"content\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The content to save.\"\n",
    "        },\n",
    "        \"filename\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The filename.\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, content: str, filename: str ):\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(content)\n",
    "        return f\"Content saved to {filename}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33cbf4-7ff8-4788-b595-9d73cbf1a2e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:23:00.453929Z",
     "iopub.status.busy": "2025-05-25T11:23:00.452390Z",
     "iopub.status.idle": "2025-05-25T11:23:00.521867Z",
     "shell.execute_reply": "2025-05-25T11:23:00.520382Z",
     "shell.execute_reply.started": "2025-05-25T11:23:00.453816Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool(), VisitWebpageTool(), \n",
    "                         PythonInterpreterTool(), WikipediaSearchTool(), FinalAnswerTool()], \n",
    "                  model=InferenceClientModel(bill_to=\"VitalNest\"),\n",
    "                  additional_authorized_imports=[\"os\", \"requests\", \"bs4\"],\n",
    "                 max_steps=10, planning_interval=2,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63367b-8496-44d6-981e-242733f59450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:23:01.188679Z",
     "iopub.status.busy": "2025-05-25T11:23:01.186566Z",
     "iopub.status.idle": "2025-05-25T11:24:33.318639Z",
     "shell.execute_reply": "2025-05-25T11:24:33.316639Z",
     "shell.execute_reply.started": "2025-05-25T11:23:01.188593Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"Search for multi latent attention in wikipedia.\n",
    "If you cannot find a wikipedia page for it, search the entire wikipedia site for it.\n",
    "          Retrieve the top search results and the relevant content.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccffb075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d2e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0c36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_agent = ToolCallingAgent(\n",
    "    model=InferenceClientModel(\n",
    "        model_id=\"Qwen/Qwen3-30B-A3B\", bill_to=\"VitalNest\", temperature=0.1\n",
    "    ),\n",
    "    tools=[\n",
    "        VisitWebpageTool(max_output_length=20_000),\n",
    "        DuckDuckGoSearchTool(max_results=5),\n",
    "    ],\n",
    "    max_steps=4,\n",
    "    verbosity_level=0,\n",
    "    name=\"web_search_agent\",\n",
    "    planning_interval=2,\n",
    "    description=\"Searches the web with a particular query.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# websearch_agent.run(\"what's multi head latent attention?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829d4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_agent = ToolCallingAgent(\n",
    "    model=InferenceClientModel(model_id=\"Qwen/Qwen3-30B-A3B\", bill_to=\"VitalNest\", temperature=.1),\n",
    "    tools=[WikipediaSearchTool(user_agent=\"WikiAssistant (merlin@example.com)\")],\n",
    "    max_steps=3,\n",
    "    verbosity_level=0,\n",
    "    name=\"wikipedia_agent\",\n",
    "    description=\"Searches Wikipedia for a topic.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce492b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent = CodeAgent(\n",
    "    tools=[PythonInterpreterTool(), FinalAnswerTool()],\n",
    "    additional_authorized_imports=[\"os\", \"requests\", \"bs4\"],\n",
    "    model=InferenceClientModel(model_id=\"Qwen/Qwen3-235B-A22B\",bill_to=\"VitalNest\", temperature=.1),\n",
    "    managed_agents=[websearch_agent, wikipedia_agent],\n",
    "    max_steps=10,\n",
    "    planning_interval=3,\n",
    "    verbosity_level=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c31461ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n**Multi-Head Latent Attention (MLA)** is an efficient attention mechanism used in large language models (LLMs). It replaces traditional Grouped Query Attention (GQA) by employing low-rank matrices and up-projection matrices to compress key-value (KV) caches, reducing memory overhead by 93% and enabling faster inference. Key features include:  \\n- **Efficiency**: Achieves a 10.6x speedup at 8K context length while maintaining output quality.  \\n- **Integration**: Central to DeepSeek models (V2/V3/R1), paired with FP8 quantization and Multi-Token Prediction.  \\n- **Technical Innovations**: Uses low-rank matrices for KV cache compression and decoupled Rotary Position Embeddings (RoPE).  \\n- **Applications**: Enables deployment of large models on consumer-grade hardware by reducing memory bottlenecks.  \\n\\n**Sources**:  \\n1. [arXiv paper (2502.07864)](https://arxiv.org/abs/2502.07864)  \\n2. [Medium article on DeepSeek-V3](https://medium.com/data-science/deepseek-v3-explained-1-multi-head-latent-attention-ed6bee2a67c4)  \\n3. [GitHub repo: mla-experiments](https://github.com/ambisinister/mla-experiments)  \\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager_agent.run(\"\"\"Search for `topic`:multi head latent attention in wikipedia.\n",
    "                  If there's no information about the same in Wikipedia, search the web \n",
    "                  for it and return a summary of the findings along with the search result links.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5891393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6f5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers.utils.import_utils import is_flash_attn_2_available\n",
    "\n",
    "from colpali_engine.models import ColQwen2_5, ColQwen2_5_Processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2026e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba3965a0962432ea889e6de249c5bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3e897980b84d238b5cedc58586704f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = ColQwen2_5.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"vidore/colqwen2.5-v0.2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",  # or \"mps\" if on Apple Silicon\n",
    "    attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else None,\n",
    ").eval()\n",
    "processor = ColQwen2_5_Processor.from_pretrained(\"vidore/colqwen2.5-v0.2\", use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc98854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your inputs\n",
    "images = [\n",
    "    Image.new(\"RGB\", (128, 128), color=\"white\"),\n",
    "    Image.new(\"RGB\", (128, 128), color=\"black\"),\n",
    "]\n",
    "queries = [\n",
    "    \"Is attention really all you need?\",\n",
    "    \"What is the amount of bananas farmed in Salvador?\",\n",
    "]\n",
    "\n",
    "# Process the inputs\n",
    "batch_images = processor.process_images(images).to(model.device)\n",
    "batch_queries = processor.process_queries(queries).to(model.device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    image_embeddings = model(**batch_images)\n",
    "    query_embeddings = model(**batch_queries)\n",
    "\n",
    "scores = processor.score_multi_vector(query_embeddings, image_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1ac9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
